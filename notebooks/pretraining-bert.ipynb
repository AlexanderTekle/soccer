{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "b33e3ad5-b6a3-4117-a9ed-817144415f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file './raw_data/combined_unlabeled_clean.txt' has 1855918 words.\n"
     ]
    }
   ],
   "source": [
    "def get_word_count(filename):\n",
    "  with open(filename, 'r') as f:\n",
    "    # Read the entire file content\n",
    "    content = f.read()\n",
    "\n",
    "    # Split the content into words, removing whitespaces\n",
    "    words = content.split()\n",
    "\n",
    "    return len(words)\n",
    "\n",
    "# Example usage\n",
    "filename = \"./raw_data/combined_unlabeled_commentary.txt\"  # Replace with your actual filename\n",
    "word_count = get_word_count(filename)\n",
    "print(f\"The file '{filename}' has {word_count} words.\")\n",
    "# print(f\"The file '{filename2}' has {word_count2} words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "6bf6f295-5cc6-413d-84c3-a8c4710b18af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text file split into sentences and saved to ./raw_data/combined_commentary_split.txt\n"
     ]
    }
   ],
   "source": [
    "def split_sentences(input_file, output_file):\n",
    "  \"\"\"\n",
    "  Splits a text file into separate lines for each sentence.\n",
    "\n",
    "  Args:\n",
    "    input_file (str): Path to the input text file.\n",
    "    output_file (str): Path to the output file where the split sentences will be written.\n",
    "  \"\"\"\n",
    "  sentences = []\n",
    "  current_sentence = \"\"\n",
    "  with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "    for line in infile:\n",
    "      # Add line to current sentence (excluding trailing newline)\n",
    "      current_sentence += line.strip()\n",
    "\n",
    "      # Check for sentence delimiters (e.g., ., ?, !) and write complete sentences\n",
    "      for delimiter in [\".\", \"?\", \"!\"]:\n",
    "        if delimiter in current_sentence:\n",
    "          if (len(current_sentence) > 8):\n",
    "            sentences.append(current_sentence.split(delimiter)[0] + delimiter + \"\\n\")\n",
    "          current_sentence = current_sentence.split(delimiter)[1].strip()\n",
    "\n",
    "      # Write any remaining sentence at the end of the file\n",
    "      # if current_sentence:\n",
    "      #   sentences.append(current_sentence)\n",
    "    outfile.writelines(sentences)\n",
    "\n",
    "# Example usage:\n",
    "input_file = \"./raw_data/combined_unlabeled_commentary.txt\"\n",
    "output_file = \"./raw_data/combined_commentary_split.txt\"  # Output file with split sentences\n",
    "\n",
    "split_sentences(input_file, output_file)\n",
    "\n",
    "print(f\"Text file split into sentences and saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "6c238d47-68de-455a-a355-e54d19c1d32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1245988"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count = get_word_count(output_file)\n",
    "word_count\n",
    "\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "6bc4ed90-20ca-41e8-9e4c-eb12bebd9094",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM, DataCollatorForLanguageModeling\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch\n",
    "\n",
    "# Define paths and hyperparameters\n",
    "model_name = \"bert-base-uncased\"  # Pre-trained BERT model\n",
    "text_file = \"./raw_data/combined_commentary_split.txt\"  # Path to your text file\n",
    "batch_size = 8  # Adjust this based on your GPU memory\n",
    "max_len = 512  # Maximum sequence length\n",
    "learning_rate = 1e-5\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "# Load tokenizer and model on chosen device\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForMaskedLM.from_pretrained(model_name).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "9b04829e-6042-4397-abf8-59f17f0c7311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to mask tokens\n",
    "def mask_sentence(sentence):\n",
    "  \"\"\"Masks 15% of the tokens in a sentence.\"\"\"\n",
    "  #print(sentence[\"text\"])\n",
    "  masked_sentence = tokenizer.batch_encode_plus(sentence[\"text\"], return_tensors=\"pt\", truncation = True, padding=\"max_length\", max_length=280)\n",
    "  masked_sentence = masked_sentence.to(device)  # Move data to device\n",
    "\n",
    "  input_ids = masked_sentence[\"input_ids\"]\n",
    "  attention_mask = masked_sentence[\"attention_mask\"]\n",
    "  labels = input_ids.clone()\n",
    "\n",
    "  # Randomly mask 15% of tokens\n",
    "  probability_mask = 0.15\n",
    "  mask_indices = torch.bernoulli(torch.ones_like(input_ids) * probability_mask).bool()\n",
    "  labels[~mask_indices] = -100  # Set padding tokens to -100\n",
    "\n",
    "  # Replace masked tokens with [MASK]\n",
    "  input_ids[mask_indices] = tokenizer.mask_token_id\n",
    "\n",
    "  print(\"check\")\n",
    "  print(input_ids.shape)\n",
    "  print(attention_mask.shape)\n",
    "\n",
    "  return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"labels\": labels}\n",
    "    \n",
    "# def collate_fn(batch):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "4df1b08a-f2e9-464f-8afc-d97c485e339e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 33568\n",
      "})\n",
      "Number of batches: 8392\n",
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 33568\n",
      "})\n",
      "{'text': 'INSIGHTSPre Match1Blackpool have won just two of their last 15 league games against Sheffield United (D6 L7), although they are unbeaten in four against the Blades (W1 D3).'}\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x28d59cbe0>\n"
     ]
    }
   ],
   "source": [
    "# Load data from text file\n",
    "small_file = \"./raw_data/combined_unlabeled_commentary_clean.txt\"\n",
    "large_file = \"./raw_data/combined_commentary_split.txt\"\n",
    "dataset = load_dataset(\"text\", data_files={\"train\": large_file}, split=\"train\")\n",
    "train_data = dataset.map(mask_sentence, batched=True)\n",
    "train_data.set_format(\"torch\")\n",
    "print(dataset)\n",
    "# for i in dataset:\n",
    "#     print(i)\n",
    "# print(type(train_data))\n",
    "# print(train_data)\n",
    "# print (len(train_data[\"text\"]))\n",
    "# print (len(train_data[\"input_ids\"]))\n",
    "# print (len(train_data[\"attention_mask\"]))\n",
    "# print (len(train_data[\"labels\"]))\n",
    "\n",
    "# print (type(train_data[\"text\"]))\n",
    "# print (type(train_data[\"input_ids\"]))\n",
    "# print (type(train_data[\"attention_mask\"]))\n",
    "# print (type(train_data[\"labels\"]))\n",
    "\n",
    "# print (train_data[\"attention_mask\"].shape)\n",
    "# print (train_data[\"attention_mask\"][0].shape)\n",
    "\n",
    "# print (train_data[\"attention_mask\"][50].shape)\n",
    "# print (train_data[\"attention_mask\"][99].shape)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=4, shuffle=True)\n",
    "num_batches = len(train_loader)\n",
    "print(f\"Number of batches: {num_batches}\")\n",
    "\n",
    "print(dataset)\n",
    "print(dataset[0])\n",
    "\n",
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "181bfc46-9bbd-456b-bc83-e9f5b9987ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num = 0\n",
    "# for i in train_dataloader:\n",
    "#     print(i[\"input_ids\"].shape)\n",
    "#     #if num%100:\n",
    "#         #print(i[\"input_ids\"].shape)\n",
    "#     # num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "a18fd44f-a866-4539-bc26-7e5bf498bbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 14.641313552856445\n",
      "Epoch: 1, Loss: 1.7769700288772583\n",
      "Epoch: 1, Loss: 1.135185718536377\n",
      "Epoch: 1, Loss: 0.697974443435669\n",
      "Epoch: 1, Loss: 0.573076069355011\n",
      "Epoch: 1, Loss: 0.45633938908576965\n",
      "Epoch: 1, Loss: 0.5330857634544373\n",
      "Epoch: 1, Loss: 0.20004169642925262\n",
      "Epoch: 1, Loss: 0.655945897102356\n",
      "Epoch: 1, Loss: 0.35381612181663513\n",
      "Epoch: 1, Loss: 0.6889758706092834\n",
      "Epoch: 1, Loss: 0.4797069728374481\n",
      "Epoch: 1, Loss: 0.3986416161060333\n",
      "Epoch: 1, Loss: 0.6535927653312683\n",
      "Epoch: 1, Loss: 0.33146506547927856\n",
      "Epoch: 1, Loss: 0.24999576807022095\n",
      "Epoch: 1, Loss: 0.21215470135211945\n",
      "Epoch: 1, Loss: 0.42111289501190186\n",
      "Epoch: 1, Loss: 0.27609488368034363\n",
      "Epoch: 1, Loss: 0.34636086225509644\n",
      "Epoch: 1, Loss: 0.3873303234577179\n",
      "Epoch: 1, Loss: 0.7174456715583801\n",
      "Epoch: 1, Loss: 0.40976354479789734\n",
      "Epoch: 1, Loss: 0.3213740885257721\n",
      "Epoch: 1, Loss: 0.5686247944831848\n",
      "Epoch: 1, Loss: 0.3610919415950775\n",
      "Epoch: 1, Loss: 0.6671115756034851\n",
      "Epoch: 1, Loss: 0.43717530369758606\n",
      "Epoch: 1, Loss: 0.20421096682548523\n",
      "Epoch: 1, Loss: 0.3158963918685913\n",
      "Epoch: 1, Loss: 0.5485988855361938\n",
      "Epoch: 1, Loss: 0.2124830186367035\n",
      "Epoch: 1, Loss: 0.2814560532569885\n",
      "Epoch: 1, Loss: 0.6841039657592773\n",
      "Epoch: 1, Loss: 0.20012648403644562\n",
      "Epoch: 1, Loss: 0.7666187882423401\n",
      "Epoch: 1, Loss: 0.35175764560699463\n",
      "Epoch: 1, Loss: 0.6015634536743164\n",
      "Epoch: 1, Loss: 0.2046135812997818\n",
      "Epoch: 1, Loss: 0.28105977177619934\n",
      "Epoch: 1, Loss: 0.48355627059936523\n",
      "Epoch: 1, Loss: 0.45117634534835815\n",
      "Epoch: 1, Loss: 0.3848505914211273\n",
      "Epoch: 1, Loss: 0.6220069527626038\n",
      "Epoch: 1, Loss: 0.48536035418510437\n",
      "Epoch: 1, Loss: 0.6241253614425659\n",
      "Epoch: 1, Loss: 0.48059895634651184\n",
      "Epoch: 1, Loss: 0.6108184456825256\n",
      "Epoch: 1, Loss: 0.2022981196641922\n",
      "Epoch: 1, Loss: 0.5036303997039795\n",
      "Epoch: 1, Loss: 0.7431279420852661\n",
      "Epoch: 1, Loss: 0.22340063750743866\n",
      "Epoch: 1, Loss: 0.6807225346565247\n",
      "Epoch: 1, Loss: 0.16805830597877502\n",
      "Epoch: 1, Loss: 0.7646757364273071\n",
      "Epoch: 1, Loss: 0.22640246152877808\n",
      "Epoch: 1, Loss: 0.40591996908187866\n",
      "Epoch: 1, Loss: 0.6264060139656067\n",
      "Epoch: 1, Loss: 0.35343676805496216\n",
      "Epoch: 1, Loss: 0.2924008369445801\n",
      "Epoch: 1, Loss: 0.6499342918395996\n",
      "Epoch: 1, Loss: 0.33666297793388367\n",
      "Epoch: 1, Loss: 0.4282826781272888\n",
      "Epoch: 1, Loss: 0.27743983268737793\n",
      "Epoch: 1, Loss: 0.4724954068660736\n",
      "Epoch: 1, Loss: 0.36346733570098877\n",
      "Epoch: 1, Loss: 0.3648500144481659\n",
      "Epoch: 1, Loss: 0.3783506155014038\n",
      "Epoch: 1, Loss: 0.3609575927257538\n",
      "Epoch: 1, Loss: 0.2231532335281372\n",
      "Epoch: 1, Loss: 0.44620972871780396\n",
      "Epoch: 1, Loss: 0.22237886488437653\n",
      "Epoch: 1, Loss: 0.3621346950531006\n",
      "Epoch: 1, Loss: 0.16575931012630463\n",
      "Epoch: 1, Loss: 0.2602756917476654\n",
      "Epoch: 1, Loss: 0.2268909215927124\n",
      "Epoch: 1, Loss: 0.44052091240882874\n",
      "Epoch: 1, Loss: 0.31446075439453125\n",
      "Epoch: 1, Loss: 0.20751896500587463\n",
      "Epoch: 1, Loss: 0.5601783990859985\n",
      "Epoch: 1, Loss: 0.2766084372997284\n",
      "Epoch: 1, Loss: 0.2490113526582718\n",
      "Epoch: 1, Loss: 0.16421328485012054\n",
      "Epoch: 1, Loss: 0.2726345956325531\n",
      "Epoch: 2, Loss: 0.10282731056213379\n",
      "Epoch: 2, Loss: 0.13896434009075165\n",
      "Epoch: 2, Loss: 0.26107972860336304\n",
      "Epoch: 2, Loss: 0.3208034336566925\n",
      "Epoch: 2, Loss: 0.4205891489982605\n",
      "Epoch: 2, Loss: 0.1368982344865799\n",
      "Epoch: 2, Loss: 0.14675691723823547\n",
      "Epoch: 2, Loss: 0.1287965476512909\n",
      "Epoch: 2, Loss: 0.3259164094924927\n",
      "Epoch: 2, Loss: 0.2987178564071655\n",
      "Epoch: 2, Loss: 0.08439463376998901\n",
      "Epoch: 2, Loss: 0.3174585998058319\n",
      "Epoch: 2, Loss: 0.3477742373943329\n",
      "Epoch: 2, Loss: 0.13565774261951447\n",
      "Epoch: 2, Loss: 0.23959405720233917\n",
      "Epoch: 2, Loss: 0.5326407551765442\n",
      "Epoch: 2, Loss: 0.28784072399139404\n",
      "Epoch: 2, Loss: 0.2548213601112366\n",
      "Epoch: 2, Loss: 0.16892796754837036\n",
      "Epoch: 2, Loss: 0.2610999047756195\n",
      "Epoch: 2, Loss: 0.18195347487926483\n",
      "Epoch: 2, Loss: 0.118592269718647\n",
      "Epoch: 2, Loss: 0.3622042238712311\n",
      "Epoch: 2, Loss: 0.27296745777130127\n",
      "Epoch: 2, Loss: 0.2803395390510559\n",
      "Epoch: 2, Loss: 0.2248128056526184\n",
      "Epoch: 2, Loss: 0.06342677026987076\n",
      "Epoch: 2, Loss: 0.20428502559661865\n",
      "Epoch: 2, Loss: 0.18320398032665253\n",
      "Epoch: 2, Loss: 0.32480406761169434\n",
      "Epoch: 2, Loss: 0.24435502290725708\n",
      "Epoch: 2, Loss: 0.2136262059211731\n",
      "Epoch: 2, Loss: 0.013446053490042686\n",
      "Epoch: 2, Loss: 0.3010169565677643\n",
      "Epoch: 2, Loss: 0.29708176851272583\n",
      "Epoch: 2, Loss: 0.052040599286556244\n",
      "Epoch: 2, Loss: 0.3270973265171051\n",
      "Epoch: 2, Loss: 0.3563571572303772\n",
      "Epoch: 2, Loss: 0.15169227123260498\n",
      "Epoch: 2, Loss: 0.1596965491771698\n",
      "Epoch: 2, Loss: 0.1297179013490677\n",
      "Epoch: 2, Loss: 0.10826952010393143\n",
      "Epoch: 2, Loss: 0.24075926840305328\n",
      "Epoch: 2, Loss: 0.07957297563552856\n",
      "Epoch: 2, Loss: 0.29720330238342285\n",
      "Epoch: 2, Loss: 0.3783527612686157\n",
      "Epoch: 2, Loss: 0.5086138844490051\n",
      "Epoch: 2, Loss: 0.15919937193393707\n",
      "Epoch: 2, Loss: 0.16936640441417694\n",
      "Epoch: 2, Loss: 0.16602560877799988\n",
      "Epoch: 2, Loss: 0.17515043914318085\n",
      "Epoch: 2, Loss: 0.19749917089939117\n",
      "Epoch: 2, Loss: 0.12496175616979599\n",
      "Epoch: 2, Loss: 0.16216221451759338\n",
      "Epoch: 2, Loss: 0.22094939649105072\n",
      "Epoch: 2, Loss: 0.2966304123401642\n",
      "Epoch: 2, Loss: 0.13121823966503143\n",
      "Epoch: 2, Loss: 0.16172952950000763\n",
      "Epoch: 2, Loss: 0.07528521865606308\n",
      "Epoch: 2, Loss: 0.19054508209228516\n",
      "Epoch: 2, Loss: 0.173354372382164\n",
      "Epoch: 2, Loss: 0.4064241349697113\n",
      "Epoch: 2, Loss: 0.20355921983718872\n",
      "Epoch: 2, Loss: 0.20760664343833923\n",
      "Epoch: 2, Loss: 0.37385573983192444\n",
      "Epoch: 2, Loss: 0.541569709777832\n",
      "Epoch: 2, Loss: 0.5601598024368286\n",
      "Epoch: 2, Loss: 0.38025081157684326\n",
      "Epoch: 2, Loss: 0.2827557325363159\n",
      "Epoch: 2, Loss: 0.20632372796535492\n",
      "Epoch: 2, Loss: 0.2196817547082901\n",
      "Epoch: 2, Loss: 0.5146868824958801\n",
      "Epoch: 2, Loss: 0.1613408774137497\n",
      "Epoch: 2, Loss: 0.2844713032245636\n",
      "Epoch: 2, Loss: 0.1413915455341339\n",
      "Epoch: 2, Loss: 0.1601324826478958\n",
      "Epoch: 2, Loss: 0.32768765091896057\n",
      "Epoch: 2, Loss: 0.30806925892829895\n",
      "Epoch: 2, Loss: 0.1952676773071289\n",
      "Epoch: 2, Loss: 0.20622853934764862\n",
      "Epoch: 2, Loss: 0.2439756691455841\n",
      "Epoch: 2, Loss: 0.4115579426288605\n",
      "Epoch: 2, Loss: 0.22694620490074158\n",
      "Epoch: 2, Loss: 0.17167845368385315\n",
      "Epoch: 3, Loss: 0.28830304741859436\n",
      "Epoch: 3, Loss: 0.14820760488510132\n",
      "Epoch: 3, Loss: 0.19407422840595245\n",
      "Epoch: 3, Loss: 0.23912599682807922\n",
      "Epoch: 3, Loss: 0.12053841352462769\n",
      "Epoch: 3, Loss: 0.1697109490633011\n",
      "Epoch: 3, Loss: 0.07291197776794434\n",
      "Epoch: 3, Loss: 0.07958041876554489\n",
      "Epoch: 3, Loss: 0.08043518662452698\n",
      "Epoch: 3, Loss: 0.1977459192276001\n",
      "Epoch: 3, Loss: 0.08386284112930298\n",
      "Epoch: 3, Loss: 0.11830801516771317\n",
      "Epoch: 3, Loss: 0.1538594514131546\n",
      "Epoch: 3, Loss: 0.17464931309223175\n",
      "Epoch: 3, Loss: 0.03758872672915459\n",
      "Epoch: 3, Loss: 0.20360618829727173\n",
      "Epoch: 3, Loss: 0.07294299453496933\n",
      "Epoch: 3, Loss: 0.11574950814247131\n",
      "Epoch: 3, Loss: 0.08340831845998764\n",
      "Epoch: 3, Loss: 0.2150208204984665\n",
      "Epoch: 3, Loss: 0.1696585714817047\n",
      "Epoch: 3, Loss: 0.18338744342327118\n",
      "Epoch: 3, Loss: 0.08905649185180664\n",
      "Epoch: 3, Loss: 0.07606001198291779\n",
      "Epoch: 3, Loss: 0.16019268333911896\n",
      "Epoch: 3, Loss: 0.11479493975639343\n",
      "Epoch: 3, Loss: 0.2801877558231354\n",
      "Epoch: 3, Loss: 0.170468270778656\n",
      "Epoch: 3, Loss: 0.2254108488559723\n",
      "Epoch: 3, Loss: 0.0679047480225563\n",
      "Epoch: 3, Loss: 0.15550751984119415\n",
      "Epoch: 3, Loss: 0.1518634557723999\n",
      "Epoch: 3, Loss: 0.152261421084404\n",
      "Epoch: 3, Loss: 0.10105130076408386\n",
      "Epoch: 3, Loss: 0.14141763746738434\n",
      "Epoch: 3, Loss: 0.04342544823884964\n",
      "Epoch: 3, Loss: 0.08414596319198608\n",
      "Epoch: 3, Loss: 0.15160979330539703\n",
      "Epoch: 3, Loss: 0.09680059552192688\n",
      "Epoch: 3, Loss: 0.1464710384607315\n",
      "Epoch: 3, Loss: 0.05951326712965965\n",
      "Epoch: 3, Loss: 0.2130863070487976\n",
      "Epoch: 3, Loss: 0.08583934605121613\n",
      "Epoch: 3, Loss: 0.11533627659082413\n",
      "Epoch: 3, Loss: 0.178278386592865\n",
      "Epoch: 3, Loss: 0.1753726750612259\n",
      "Epoch: 3, Loss: 0.1014736220240593\n",
      "Epoch: 3, Loss: 0.11199178546667099\n",
      "Epoch: 3, Loss: 0.13308729231357574\n",
      "Epoch: 3, Loss: 0.04982035607099533\n",
      "Epoch: 3, Loss: 0.11583121865987778\n",
      "Epoch: 3, Loss: 0.20810890197753906\n",
      "Epoch: 3, Loss: 0.2842118442058563\n",
      "Epoch: 3, Loss: 0.2247914969921112\n",
      "Epoch: 3, Loss: 0.06799008697271347\n",
      "Epoch: 3, Loss: 0.13180197775363922\n",
      "Epoch: 3, Loss: 0.0779360979795456\n",
      "Epoch: 3, Loss: 0.2520659863948822\n",
      "Epoch: 3, Loss: 0.09409838914871216\n",
      "Epoch: 3, Loss: 0.20060326159000397\n",
      "Epoch: 3, Loss: 0.10301358997821808\n",
      "Epoch: 3, Loss: 0.427436888217926\n",
      "Epoch: 3, Loss: 0.1988430768251419\n",
      "Epoch: 3, Loss: 0.20572097599506378\n",
      "Epoch: 3, Loss: 0.14999434351921082\n",
      "Epoch: 3, Loss: 0.16767697036266327\n",
      "Epoch: 3, Loss: 0.22843940556049347\n",
      "Epoch: 3, Loss: 0.09671703726053238\n",
      "Epoch: 3, Loss: 0.13687461614608765\n",
      "Epoch: 3, Loss: 0.23707710206508636\n",
      "Epoch: 3, Loss: 0.18910065293312073\n",
      "Epoch: 3, Loss: 0.13194170594215393\n",
      "Epoch: 3, Loss: 0.046283651143312454\n",
      "Epoch: 3, Loss: 0.23649504780769348\n",
      "Epoch: 3, Loss: 0.03314751759171486\n",
      "Epoch: 3, Loss: 0.06655450910329819\n",
      "Epoch: 3, Loss: 0.20095092058181763\n",
      "Epoch: 3, Loss: 0.23941127955913544\n",
      "Epoch: 3, Loss: 0.21032410860061646\n",
      "Epoch: 3, Loss: 0.20920342206954956\n",
      "Epoch: 3, Loss: 0.22057193517684937\n",
      "Epoch: 3, Loss: 0.21223245561122894\n",
      "Epoch: 3, Loss: 0.15763457119464874\n",
      "Epoch: 3, Loss: 0.19936972856521606\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):  # Adjust number of epochs\n",
    "  i=0\n",
    "  for batch in train_loader:\n",
    "    #print(batch)\n",
    "    # Move data to device\n",
    "    #batch.to(device)\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    labels = batch[\"labels\"].to(device)\n",
    "    #print(batch[\"text\"])\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(input_ids= input_ids, attention_mask=attention_mask, labels=labels)\n",
    "    loss = outputs.loss\n",
    "\n",
    "    # Backward pass and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print training progress (optional)\n",
    "    if i%100 == 0:\n",
    "      print(f\"Epoch: {epoch+1}, Loss: {loss}\")\n",
    "    i+=1;\n",
    "\n",
    "# Save the fine-tuned model (optional)\n",
    "model.save_pretrained(\"masked_lm_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4eca48-852d-47ca-9d7d-36f49017993c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "e45ac05b-b6e3-4b0d-8436-1558c20412a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b030260c-176e-4936-87dd-3fe0ea80a6a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-3-8-19",
   "language": "python",
   "name": "python-3-8-19"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
