{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4469aaee-0415-48bf-9f07-5aa93fb71162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: USE_MPS=1\n",
      "env: USE_PYTORCH_METAL=1\n"
     ]
    }
   ],
   "source": [
    "%env USE_MPS=1\n",
    "\n",
    "%env USE_PYTORCH_METAL=1\n",
    "\n",
    "# %env PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.7 ./webui.sh --precision full --no-half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e13ec1e-27a4-4fbd-a7de-7c44d3b14259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.19\n"
     ]
    }
   ],
   "source": [
    "!python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2f0a449-7ce1-4a2d-bb23-a2a506df79fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4a5a527-9e02-4a57-a0e2-2d1c14505b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "#verify mps is available\n",
    "import torch\n",
    "torch.set_default_device(\"mps\")\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")\n",
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e8df03c-35b3-42a2-99f0-8bcdf665b7d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ID', 'Tweet', 'anger', 'anticipation', 'disgust', 'fear', 'joy', 'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust'],\n",
       "        num_rows: 6838\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['ID', 'Tweet', 'anger', 'anticipation', 'disgust', 'fear', 'joy', 'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust'],\n",
       "        num_rows: 3259\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['ID', 'Tweet', 'anger', 'anticipation', 'disgust', 'fear', 'joy', 'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust'],\n",
       "        num_rows: 886\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### import torch\n",
    "from transformers import BertModel \n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "# model = BertModel.from_pretrained(\"bert-base-uncased\", torch_dtype=torch.float16, attn_implementation=\"sdpa\")\n",
    "dataset = load_dataset(\"sem_eval_2018_task_1\", \"subtask5.english\").with_format(\"torch\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9300a507-03f4-4eba-8745-2cf045841338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import transformers\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertModel, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c88e8c4-6902-4328-8622-bcb2d5c6fa9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID': '2017-En-21441',\n",
       " 'Tweet': \"â€œWorry is a down payment on a problem you may never have'. \\xa0Joyce Meyer.  #motivation #leadership #worry\",\n",
       " 'anger': tensor(False, device='mps:0'),\n",
       " 'anticipation': tensor(True, device='mps:0'),\n",
       " 'disgust': tensor(False, device='mps:0'),\n",
       " 'fear': tensor(False, device='mps:0'),\n",
       " 'joy': tensor(False, device='mps:0'),\n",
       " 'love': tensor(False, device='mps:0'),\n",
       " 'optimism': tensor(True, device='mps:0'),\n",
       " 'pessimism': tensor(False, device='mps:0'),\n",
       " 'sadness': tensor(False, device='mps:0'),\n",
       " 'surprise': tensor(False, device='mps:0'),\n",
       " 'trust': tensor(True, device='mps:0')}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset\n",
    "# dataset['train'][0]\n",
    "# dataset['train'].set_format(\"torch\", device=\"mps\") \n",
    "# dataset['validation'].set_format(\"torch\", device=\"mps\") \n",
    "# dataset.set_format(\"torch\", device=\"mps\") \n",
    "\n",
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b34ea7b-2238-4dc9-95e5-14fb31b93865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger',\n",
       " 'anticipation',\n",
       " 'disgust',\n",
       " 'fear',\n",
       " 'joy',\n",
       " 'love',\n",
       " 'optimism',\n",
       " 'pessimism',\n",
       " 'sadness',\n",
       " 'surprise',\n",
       " 'trust']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [label for label in dataset['train'].features.keys() if label not in ['ID', 'Tweet']]\n",
    "id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "label2id = {label:idx for idx, label in enumerate(labels)}\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf586d6-b058-41d2-93d1-94b17c60c36d",
   "metadata": {},
   "source": [
    "Now we are getting ready to preprocess the data using the BERT tokenizer. This include mapping the text to float ing point labels and moving it into a matrix of size batch_size x num_labels. These should be floats per PyTorch expectation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3faca06f-1226-4c3e-86b3-90cef8c2f9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def preprocess_data(examples):\n",
    "    #get the text of this batch\n",
    "    text=examples[\"Tweet\"]\n",
    "    #get the ecoding for this text tusing bert tokenizer\n",
    "    encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length = 128)\n",
    "    #add labels\n",
    "    labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n",
    "    #numpy array size batch x num labels\n",
    "    labels_matrix = np.zeros((len(text), len(labels)))\n",
    "\n",
    "    # replace zeros in numpy array with values from encoding\n",
    "    for idx, label in enumerate(labels):\n",
    "        labels_matrix[:, idx] = labels_batch[label]\n",
    "\n",
    "    encoding[\"labels\"] = labels_matrix.tolist()\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bc3c030-2c15-40f2-a031-f655bdfb4ea2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoded_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m text \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m5\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTweet\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mlen\u001b[39m(text)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mencoded_dataset\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'encoded_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "text = dataset['train'][5]['Tweet']\n",
    "len(text)\n",
    "# encoded_dataset['train']['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12db118d-a036-4400-b1cf-8f06ec703eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 6838\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3259\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 886\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset = dataset.map(preprocess_data, batched=True, remove_columns=dataset['train'].column_names)\n",
    "# encoded_dataset\n",
    "# encoded_dataset[\"train\"]\n",
    "# encoded_dataset[\"validation\"]\n",
    "# encoded_dataset[\"train\"][\"input_ids\"]\n",
    "# encoded_dataset.with_format(\"torch\")\n",
    "# torch.Tensor(encoded_dataset)\n",
    "encoded_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5f12a55-c0c5-47d9-84cd-64799eb05883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  1523,  4737,  ...,     0,     0,     0],\n",
       "        [  101,  3649,  2017,  ...,     0,     0,     0],\n",
       "        [  101,  1030,  4098,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  1030, 21541,  ...,     0,     0,     0],\n",
       "        [  101,  1045,  4687,  ...,     0,     0,     0],\n",
       "        [  101,  1045,  1005,  ...,     0,     0,     0]], device='mps:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset['train'].set_format(\"torch\", device=\"mps\") \n",
    "encoded_dataset['validation'].set_format(\"torch\", device=\"mps\") \n",
    "encoded_dataset.set_format(\"torch\", device=\"mps\") \n",
    "encoded_dataset[\"train\"]\n",
    "encoded_dataset[\"validation\"]\n",
    "encoded_dataset[\"train\"][\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c12d174-0585-475e-9d37-410c982e4d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.], device='mps:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = encoded_dataset['train'][0]\n",
    "print(example.keys())\n",
    "\n",
    "len(example['input_ids'])\n",
    "example['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3979663-73f4-4ef8-855e-b01600980276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.decode(example['input_ids'])\n",
    "#CLS = classify token and it is placed at the beginning of input\n",
    "#SEP = end of string used for next sentence prediction\n",
    "#PAD = pad to 128 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "875851ae-4303-47dc-a210-da260efcc504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.], device='mps:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed831f78-7756-433e-b8fd-09375cb2aaa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anticipation', 'optimism', 'trust']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[id2label[idx] for idx, label in enumerate(example['labels']) if label == 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc1a5a1-49a1-4dcd-81f0-f1a51ce855c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b8cdbdb-9a25-4397-9853-708c056b06c5",
   "metadata": {},
   "source": [
    "Setup model. multi_label_classification indicates the type of problem. We'll use BCEWithLogitsLoss (sigmoid layer with binary cross entropy loss - BCEWithLogitsLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12cb5052-17ea-4b52-a4dd-c4aafe782372",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", \n",
    "                                                           problem_type=\"multi_label_classification\", \n",
    "                                                           num_labels=len(labels),\n",
    "                                                           id2label=id2label,\n",
    "                                                           label2id=label2id)\n",
    "model = model.to(device)\n",
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67c3a403-4483-4402-8d56-5b492f952e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "metric_name = \"f1\"\n",
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "623f56d5-53d8-4c40-98bd-99af3f93d932",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/python3-8-19/lib/python3.8/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/python3-8-19/lib/python3.8/site-packages/transformers/training_args.py:2127: UserWarning: `use_mps_device` is deprecated and will be removed in version 5.0 of ðŸ¤— Transformers. `mps` device will be used by default if available similar to the way `cuda` device is used.Therefore, no action from user is required. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    f\"bert-finetuned-sem_eval-english\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    "    use_mps_device=True\n",
    "    #push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "111f9e47-3494-4466-b269-9ae0c18ff3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "    \n",
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid(device=model.device)\n",
    "    probs = sigmoid(torch.Tensor(predictions, device=device))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    # return as dictionary\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "               'roc_auc': roc_auc,\n",
    "               'accuracy': accuracy}\n",
    "    return metrics\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, \n",
    "            tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds, \n",
    "        labels=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ce549f8-9a78-49bd-aa89-3ebc58d94022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.mps.FloatTensor'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset['train'][0]['labels'].type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6637f2c-26d1-48cc-a093-e3aa190928fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 6838\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df5333e0-e77a-4a5a-887e-06f5aec427fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "train_dataset = TensorDataset(encoded_dataset[\"train\"][\"input_ids\"], \n",
    "                             encoded_dataset[\"train\"][\"attention_mask\"],\n",
    "                             encoded_dataset[\"train\"][\"labels\"]);\n",
    "batch_size = 16  # Adjust based on your GPU memory\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "eval_loader = DataLoader(encoded_dataset[\"validation\"], batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "# train_loader.to(device)\n",
    "\n",
    "# encoded_dataset['train'].set_format(\"torch\", device=\"mps\")\n",
    "# encoded_dataset['validation'].set_format(\"torch\", device=\"mps\")\n",
    "#dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5d865f2-0d00-4c86-892c-290c0f7c42cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0.,  ..., 0., 0., 1.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='mps:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# outputs = model(input_ids=encoded_dataset['train']['input_ids'][0].unsqueeze(0), \n",
    "#                 labels=encoded_dataset['train'][0]['labels'].unsqueeze(0),\n",
    "#                 attention_mask=encoded_dataset['train'][0]['attention_mask'].unsqueeze(0))\n",
    "\n",
    "encoded_dataset['train'].set_format(\"torch\", device=\"mps\")\n",
    "encoded_dataset['train'][\"labels\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64fcf239-71d5-4669-980e-d3585c621142",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b79afb3-3e02-4b22-a401-9471c29611e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72966577-2650-472d-a012-73ce856b6a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{tensor(0.), tensor(1.)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one = set(torch.tensor(np.unique(encoded_dataset['train'][\"labels\"].cpu())).cpu())\n",
    "\n",
    "# one = set(np.unique(encoded_dataset['train'][\"labels\"].cpu()))\n",
    "# one \n",
    "one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "154733c2-3c93-45d9-8961-f87d52de6b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{tensor([0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1.]),\n",
       " tensor([0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.]),\n",
       " tensor([1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0.]),\n",
       " tensor([1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0.]),\n",
       " tensor([1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.]),\n",
       " tensor([0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.]),\n",
       " tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1.]),\n",
       " tensor([0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.]),\n",
       " tensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.]),\n",
       " tensor([1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0.]),\n",
       " tensor([1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0.]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.]),\n",
       " tensor([1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.]),\n",
       " tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0.]),\n",
       " tensor([1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.]),\n",
       " tensor([0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.]),\n",
       " tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1.]),\n",
       " tensor([1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " tensor([0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0.]),\n",
       " tensor([1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.]),\n",
       " tensor([0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0.]),\n",
       " ...}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainer.train()\n",
    "two = set(encoded_dataset['train'][\"labels\"].cpu())\n",
    "two\n",
    "# two = set(encoded_dataset['train'][\"labels\"].cpu())\n",
    "# two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c15344-3dfe-44eb-bd93-4309a20a25f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two - one\n",
    "\n",
    "# if (two - one):\n",
    "#     print(\"hello\")\n",
    "# else: \n",
    "#     print(\"helloooo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35791d1c-f616-4b24-931e-c99ad96a41df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# #compute the class weights\n",
    "# encoded_dataset['train'][\"labels\"]\n",
    "# torch.tensor(encoded_dataset['train'][\"labels\"]).tolist()\n",
    "# class_wts = compute_class_weight(class_weight = 'balanced', \n",
    "#                                  classes = np.unique(encoded_dataset['train'][\"labels\"].cpu()),\n",
    "#                                  y = encoded_dataset['train'][\"labels\"].cpu())\n",
    "\n",
    "# # print(class_wts)\n",
    "# # weights= torch.tensor(class_wts,dtype=torch.float)\n",
    "# # weights = weights.to(device)\n",
    "\n",
    "# # print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c9e2e54-4093-4b23-a9fe-28cea094d71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "cross_entropy  = nn.NLLLoss() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4fd476aa-3f20-491e-ad49-ebfdd55f0648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "    # empty list to save model predictions\n",
    "    total_preds=[]\n",
    "    total_labels =[]\n",
    "  \n",
    "    # iterate over batches\n",
    "    for step,batch in enumerate(train_loader):\n",
    "    \n",
    "        # progress update after every 50 batches.\n",
    "        if step % 100 == 0 and not step == 0:\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_loader)))\n",
    "\n",
    "        # push the batch to gpu\n",
    "        batch = [r.to(device) for r in batch]\n",
    "\n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        # clear previously calculated gradients \n",
    "        model.zero_grad()        \n",
    "\n",
    "        # get model predictions for the current batch\n",
    "        preds = model(sent_id, mask)\n",
    "\n",
    "        # compute the loss between actual and predicted values\n",
    "        print (preds.logits)\n",
    "        print (labels)\n",
    "        print (preds.logits.shape)\n",
    "        print (labels.shape)\n",
    "        print (preds.logits.squeeze().shape)\n",
    "        print (labels.squeeze().shape)\n",
    "        loss = cross_entropy(preds.logits, labels)\n",
    "\n",
    "        # add on to the total loss\n",
    "        total_loss = total_loss + loss.item()\n",
    "\n",
    "        # backward pass to calculate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # update parameters\"\n",
    "        optimizer.step()\n",
    "\n",
    "        # model predictions are stored on GPU. So, push it to CPU\n",
    "        preds = preds.detach().cpu().numpy()\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "        # append the model predictions\n",
    "        total_preds+=list(preds)\n",
    "        total_labels+=labels.tolist()\n",
    "\n",
    "    # compute the training loss of the epoch\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    #total_preds  = np.concatenate(total_preds, axis=0)\n",
    "    f1 = f1_score(total_labels, total_preds, average='weighted')\n",
    "    #returns the loss and predictions\n",
    "    return avg_loss, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f8a08cc9-d641-4c5f-9f37-bc72a219da0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Placeholder storage has not been allocated on MPS device!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m train_loss\n",
      "Cell \u001b[0;32mIn[40], line 26\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()        \n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# get model predictions for the current batch\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msent_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# compute the loss between actual and predicted values\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m (preds\u001b[38;5;241m.\u001b[39mlogits)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/python3-8-19/lib/python3.8/site-packages/torch/nn/modules/module.py:1716\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1716\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/python3-8-19/lib/python3.8/site-packages/torch/nn/modules/module.py:1727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1723\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1724\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1725\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1726\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1727\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1730\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/python3-8-19/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:1695\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1687\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1688\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1691\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1692\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1693\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1695\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1696\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1701\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1702\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1703\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1705\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1707\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1709\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/python3-8-19/lib/python3.8/site-packages/torch/nn/modules/module.py:1716\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1716\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/python3-8-19/lib/python3.8/site-packages/torch/nn/modules/module.py:1727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1723\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1724\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1725\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1726\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1727\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1730\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/python3-8-19/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:1077\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1075\u001b[0m         token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m-> 1077\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1086\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((batch_size, seq_length \u001b[38;5;241m+\u001b[39m past_key_values_length), device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/python3-8-19/lib/python3.8/site-packages/torch/nn/modules/module.py:1716\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1716\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/python3-8-19/lib/python3.8/site-packages/torch/nn/modules/module.py:1727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1723\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1724\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1725\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1726\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1727\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1730\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/python3-8-19/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:210\u001b[0m, in \u001b[0;36mBertEmbeddings.forward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    207\u001b[0m         token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 210\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m token_type_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_type_embeddings(token_type_ids)\n\u001b[1;32m    213\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m token_type_embeddings\n",
      "File \u001b[0;32m/opt/anaconda3/envs/python3-8-19/lib/python3.8/site-packages/torch/nn/modules/module.py:1716\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1716\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/python3-8-19/lib/python3.8/site-packages/torch/nn/modules/module.py:1727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1723\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1724\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1725\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1726\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1727\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1730\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/python3-8-19/lib/python3.8/site-packages/torch/nn/modules/sparse.py:190\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/python3-8-19/lib/python3.8/site-packages/torch/nn/functional.py:2516\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2446\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Generate a simple lookup table that looks up embeddings in a fixed dictionary and size.\u001b[39;00m\n\u001b[1;32m   2447\u001b[0m \n\u001b[1;32m   2448\u001b[0m \u001b[38;5;124;03mThis module is often used to retrieve word embeddings using indices.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2513\u001b[0m \u001b[38;5;124;03m             [ 0.6262,  0.2438,  0.7471]]])\u001b[39;00m\n\u001b[1;32m   2514\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight):\n\u001b[0;32m-> 2516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2517\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2518\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2519\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2525\u001b[0m \u001b[43m        \u001b[49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2526\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2527\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m padding_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2528\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m padding_idx \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/python3-8-19/lib/python3.8/site-packages/torch/overrides.py:1715\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_torch_function_mode_enabled():\n\u001b[1;32m   1712\u001b[0m     \u001b[38;5;66;03m# if we're here, the mode must be set to a TorchFunctionStackMode\u001b[39;00m\n\u001b[1;32m   1713\u001b[0m     \u001b[38;5;66;03m# this unsets it and calls directly into TorchFunctionStackMode's torch function\u001b[39;00m\n\u001b[1;32m   1714\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _pop_mode_temporarily() \u001b[38;5;28;01mas\u001b[39;00m mode:\n\u001b[0;32m-> 1715\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mmode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1716\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/envs/python3-8-19/lib/python3.8/site-packages/torch/utils/_device.py:79\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/python3-8-19/lib/python3.8/site-packages/torch/nn/functional.py:2551\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2547\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2548\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2549\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2550\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Placeholder storage has not been allocated on MPS device!"
     ]
    }
   ],
   "source": [
    "train_loss = train()\n",
    "train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5d1ecb-6caa-411d-a243-51d1a8aa08c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd6beb4-8be3-48ac-ace8-a4eff6cd545d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-3-8-19",
   "language": "python",
   "name": "python-3-8-19"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
